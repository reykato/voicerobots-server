<!DOCTYPE HTML>
<!--
 This file contains code from the JoyStick Project (https://github.com/bobboteck/JoyStick).
 Copyright (c) 2015 Roberto D'Amico (Bobboteck).
-->
<html>

<head>
    <title>RPi Joystick</title>
    <meta charset="utf-8">
    <meta name="description" content="Joystick to control robot through websockets">
    <script src="/static/joy.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.1.2/socket.io.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="/static/style.css">
</head>

<body>
    <div class="container">
        <div class="row">
            <div class="col">
                <img class="rounded img-fluid" src="{{ url_for('video_feed') }}">
            </div>
            <div class="col">
                <div class="row">
                    <h1>Joystick Control</h1>
                    <h4>overrides autonomous control</h4>
                    <div id="joyDiv" style="width:300px;height:300px;margin:50px;"></div>
                </div>
                <div class="row">
                    <div class="form-group row">
                        <label for="exampleInputEmail1">Command</label>
                        <input type="text" class="form-control" id="textInput" placeholder="Enter Command">
                        <button type="submit" class="btn btn-primary" onclick="submitText()">Send</button>
                        <button type="button" class="audio-control" onclick="audio()">Capture Audio 10s</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- load OpusMediaRecorder.umd.js. OpusMediaRecorder will be loaded. -->
    <script src="https://cdn.jsdelivr.net/npm/opus-media-recorder@latest/OpusMediaRecorder.umd.js"></script>
    <!-- load encoderWorker.umd.js. This should be after OpusMediaRecorder. -->
    <!-- This script tag will create OpusMediaRecorder.encoderWorker. -->
    <script src="https://cdn.jsdelivr.net/npm/opus-media-recorder@latest/encoderWorker.umd.js"></script>

    <script type="text/javascript">
        const openaikey = "NO API KEY";

        var socket = io();
        socket.on('connect', function () {
            socket.emit('my event', { data: 'I\'m connected!' });
        });

        var joyParam = {
            "title": "joystick",
            internalFillColor: '#00b2d1',
            internalStrokeColor: '#008096',
            externalStrokeColor: '#FFFFFF'
        };
        var Joy = new JoyStick('joyDiv', joyParam);


        const audio = () => {
            let chunks = [];

            navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {

                const workerOptions = {
                    OggOpusEncoderWasmPath: 'https://cdn.jsdelivr.net/npm/opus-media-recorder@latest/OggOpusEncoder.wasm',
                    WebMOpusEncoderWasmPath: 'https://cdn.jsdelivr.net/npm/opus-media-recorder@latest/WebMOpusEncoder.wasm'
                };

                window.MediaRecorder = OpusMediaRecorder;
                let mediaRecorder = new MediaRecorder(stream, {}, workerOptions);

                mediaRecorder.start(1000);
                console.log(mediaRecorder.state)
                mediaRecorder.ondataavailable = (e) => {
                    // console.log("data available");
                    chunks.push(e.data);
                };
                setTimeout(() => {
                    mediaRecorder.stop();
                    send_audio_data(chunks);
                }, 10000)
            })
        }

        async function send_audio_data(chunks) {
            if (chunks.length !== 0) {
                const blob = new Blob(chunks, { mimeType: 'audio/webm' });
                const audioFile = new File([blob], 'recording.webm', { mimeType: 'audio/webm' });

                const formData = new FormData()
                formData.append('file', audioFile)
                formData.append('model', 'whisper-1')
                formData.append('response_format', 'text')

                const headers = new Headers()
                headers.append('Authorization', `Bearer ${openaikey}`)

                fetch("https://api.openai.com/v1/audio/transcriptions", {
                    method: 'POST',
                    body: formData,
                    headers: headers
                }).then(response => {
                    response.text().then((result) => {
                        document.getElementById("textInput").value = result
                        gpt(result);
                    })
                    console.log(response);
                    return response;
                }).catch(error => console.error(error))

                // socket.emit('audio', blob);
                // console.log("audio sent");
                // console.log(blob);
                chunks = [];
            }
        }

        async function gpt(result) {
            const headers = new Headers()
            headers.append('Authorization', `Bearer ${openaikey}`)
            headers.append('Content-Type', 'application/json')

            const requestBody = {
                model: 'gpt-3.5-turbo',
                messages: [
                    { role: 'system', content: `You are aiding in the process of running a robot using natural langauge. 
                            You will receive a command from a user directed to the robot, and you will parse it into a command that the robot can accept. 
                            You will intuit the semantic meaning of the user's command to produce an appropriate command.
                            The format of the commands you will output is exactly created by the following CFG: 

                            Command -> StopCommand | StartCommand
                            StopCommand -> stop
                            StartCommand -> start ModeCommand
                            ModeCommand -> search ColorCommand | voice DirectionalCommand
                            ColorCommand -> red | green
                            DirectionalCommand -> forward | left turn | right turn | spin

                            Explanations of the terminals:
                            stop: If the user wishes to stop the robot, the command will only be stop. 
                            start: If the user wishes to do anything but stop the robot, the command will include start.
                            search: If the user wishes the robot to search for a target, the command will include search.
                            voice: If the user wishes to manually command the robot to move, the command will include voice.
                            red/green: The color of the target the user wants the robot to search for. Default to green.
                            forward/left turn/right turn/spin: Physical movement commands. Do not default to any.
                            
                            For the system's benefit, only output the command or list of commands and no extra tokens. Thanks!`},
                    { role: 'user', content: result }
                ],
                max_tokens: 100
            }

            fetch("https://api.openai.com/v1/chat/completions", {
                method: 'POST',
                body: JSON.stringify(requestBody),
                headers: headers
            }).then(response => {
                response.json().then((result) => {
                    document.getElementById("textInput").value = result.choices[0].message.content
                    console.log(result);
                })
                return response;
            }).catch(error => console.error(error))
        }


        function send_joystick_data() {
            var entry = {
                x: Joy.GetX(),
                y: Joy.GetY()
            }

            fetch(`${window.origin}/joystick/data`, {
                method: "POST",
                credentials: "omit",
                body: JSON.stringify(entry),
                cache: "no-cache",
                headers: new Headers({
                    "content-type": "application/json"
                })
            })
        }

        function send_joystick_data_websocket() {
            var entry = {
                x: Joy.GetX(),
                y: Joy.GetY()
            }

            socket.emit('json', entry);
        }

        setInterval(send_joystick_data_websocket, 100);

        // Handles submitting text via the textbox and submit button
        function submitText() {
            var textValue = document.getElementById("textInput").value;
            fetch('/submit_text', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: textValue }),
            })
        }
    </script>
</body>

</html>